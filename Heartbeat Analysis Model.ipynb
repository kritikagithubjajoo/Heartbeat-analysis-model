{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 80 data points (columns). This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "You will use the **hearbeat_cleaned.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as T1 from T80 are the time steps on the timeline (there are 80 time steps, each time step has only one measurement). \n",
    "\n",
    "The last column is the target variable. It shows the label (category) of the measurement as follows:<br>\n",
    "0 = Normal<br>\n",
    "1 = Supraventricular premature beat<br>\n",
    "2 = Premature ventricular contraction<br>\n",
    "3 = Fusion of ventricular and normal beat<br>\n",
    "4 = Unclassifiable beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **hearbeat_cleaned.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T80**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "The data is cleaned up. There are no unqueal length sequences. And, there is no zero padding. So, you shouldn't use any `Masking` layer (like I mentioned in the lecture). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T72</th>\n",
       "      <th>T73</th>\n",
       "      <th>T74</th>\n",
       "      <th>T75</th>\n",
       "      <th>T76</th>\n",
       "      <th>T77</th>\n",
       "      <th>T78</th>\n",
       "      <th>T79</th>\n",
       "      <th>T80</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
       "0  0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
       "1  1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
       "2  1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
       "3  1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
       "4  1.000  0.833  0.309  0.0191  0.1010  0.1200  0.1040  0.0874  0.0765   \n",
       "\n",
       "      T10  ...     T72     T73     T74     T75    T76     T77     T78    T79  \\\n",
       "0  0.1380  ...  0.1970  0.1970  0.1960  0.2030  0.201  0.1990  0.2010  0.205   \n",
       "1  0.0781  ...  0.1950  0.1910  0.1520  0.1720  0.207  0.2110  0.2070  0.207   \n",
       "2  0.0857  ...  0.2260  0.2420  0.2440  0.2860  0.468  0.8160  0.9770  0.452   \n",
       "3  0.0155  ...  0.0851  0.0747  0.0515  0.0593  0.067  0.0361  0.1210  0.451   \n",
       "4  0.0765  ...  0.2050  0.4210  0.8030  0.9510  0.467  0.0000  0.0519  0.082   \n",
       "\n",
       "      T80  Target  \n",
       "0  0.2080       0  \n",
       "1  0.1720       0  \n",
       "2  0.0519       0  \n",
       "3  0.8690       0  \n",
       "4  0.0628       0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the data\n",
    "heartbeat = pd.read_csv(\"heartbeat_cleaned.csv\")\n",
    "heartbeat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7960, 81)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartbeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heartbeat['Target']\n",
    "x = heartbeat.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variables need to be an array with integer type\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_y = train_y.astype(np.int32)\n",
    "test_y = test_y.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 0, 2, 2, 0, 0, 4, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the first 10 values of the train_y data set\n",
    "train_y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert input variables to a 2-D array with float data type\n",
    "train_x= np.array(train_x)\n",
    "test_x= np.array(test_x)\n",
    "\n",
    "train_x = train_x.astype(np.float32)\n",
    "test_x = test_x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.    , 0.818 , 0.133 , ..., 0.354 , 0.354 , 0.387 ],\n",
       "       [1.    , 0.849 , 0.166 , ..., 0.108 , 0.0811, 0.0695],\n",
       "       [0.    , 0.0335, 0.163 , ..., 0.62  , 0.624 , 0.606 ],\n",
       "       ...,\n",
       "       [1.    , 0.98  , 0.573 , ..., 0.057 , 0.038 , 0.0418],\n",
       "       [0.564 , 0.512 , 0.468 , ..., 0.357 , 0.348 , 0.354 ],\n",
       "       [0.799 , 0.683 , 0.564 , ..., 0.265 , 0.265 , 0.247 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras expects a different input format:\n",
    "#Data needs to have 3 dimensions\n",
    "\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 80, 1), (5572,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.    ],\n",
       "        [0.818 ],\n",
       "        [0.133 ],\n",
       "        ...,\n",
       "        [0.354 ],\n",
       "        [0.354 ],\n",
       "        [0.387 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.849 ],\n",
       "        [0.166 ],\n",
       "        ...,\n",
       "        [0.108 ],\n",
       "        [0.0811],\n",
       "        [0.0695]],\n",
       "\n",
       "       [[0.    ],\n",
       "        [0.0335],\n",
       "        [0.163 ],\n",
       "        ...,\n",
       "        [0.62  ],\n",
       "        [0.624 ],\n",
       "        [0.606 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.98  ],\n",
       "        [0.573 ],\n",
       "        ...,\n",
       "        [0.057 ],\n",
       "        [0.038 ],\n",
       "        [0.0418]],\n",
       "\n",
       "       [[0.564 ],\n",
       "        [0.512 ],\n",
       "        [0.468 ],\n",
       "        ...,\n",
       "        [0.357 ],\n",
       "        [0.348 ],\n",
       "        [0.354 ]],\n",
       "\n",
       "       [[0.799 ],\n",
       "        [0.683 ],\n",
       "        [0.564 ],\n",
       "        ...,\n",
       "        [0.265 ],\n",
       "        [0.265 ],\n",
       "        [0.247 ]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.582035\n",
       "4    0.198995\n",
       "2    0.155402\n",
       "1    0.055905\n",
       "3    0.007663\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartbeat['Target'].value_counts()/len(heartbeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a cross-sectional shallow model using Keras (with only one hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.SimpleRNN(5, activation='softmax' , input_shape=[n_steps, n_inputs]),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 1.2218 - accuracy: 0.5774 - val_loss: 1.1084 - val_accuracy: 0.5930\n",
      "Epoch 2/80\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.1199 - accuracy: 0.5774 - val_loss: 1.0942 - val_accuracy: 0.5930\n",
      "Epoch 3/80\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 1.1111 - accuracy: 0.5635 - val_loss: 1.0860 - val_accuracy: 0.5775\n",
      "Epoch 4/80\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 1.1083 - accuracy: 0.5628 - val_loss: 1.0846 - val_accuracy: 0.5611\n",
      "Epoch 5/80\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 1.1079 - accuracy: 0.5528 - val_loss: 1.0967 - val_accuracy: 0.5389\n",
      "Epoch 6/80\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 1.1073 - accuracy: 0.5472 - val_loss: 1.0828 - val_accuracy: 0.5812\n",
      "Epoch 7/80\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 1.1063 - accuracy: 0.5499 - val_loss: 1.0821 - val_accuracy: 0.5465\n",
      "Epoch 8/80\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.1061 - accuracy: 0.5431 - val_loss: 1.0871 - val_accuracy: 0.5427\n",
      "Epoch 9/80\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.1049 - accuracy: 0.5443 - val_loss: 1.0766 - val_accuracy: 0.5649\n",
      "Epoch 10/80\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 1.1016 - accuracy: 0.5463 - val_loss: 1.0756 - val_accuracy: 0.5632\n",
      "Epoch 11/80\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0989 - accuracy: 0.5524 - val_loss: 1.0711 - val_accuracy: 0.5632\n",
      "Epoch 12/80\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0951 - accuracy: 0.5650 - val_loss: 1.0743 - val_accuracy: 0.5888\n",
      "Epoch 13/80\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 1.0903 - accuracy: 0.5802 - val_loss: 1.0682 - val_accuracy: 0.5980\n",
      "Epoch 14/80\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0854 - accuracy: 0.5879 - val_loss: 1.0561 - val_accuracy: 0.6185\n",
      "Epoch 15/80\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0800 - accuracy: 0.6012 - val_loss: 1.1748 - val_accuracy: 0.4636\n",
      "Epoch 16/80\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0763 - accuracy: 0.6052 - val_loss: 1.0498 - val_accuracy: 0.6181\n",
      "Epoch 17/80\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0743 - accuracy: 0.6077 - val_loss: 1.1227 - val_accuracy: 0.5804\n",
      "Epoch 18/80\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0674 - accuracy: 0.6131 - val_loss: 1.0407 - val_accuracy: 0.6273\n",
      "Epoch 19/80\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 1.0684 - accuracy: 0.6147 - val_loss: 1.0671 - val_accuracy: 0.5984\n",
      "Epoch 20/80\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0631 - accuracy: 0.6217 - val_loss: 1.0430 - val_accuracy: 0.6319\n",
      "Epoch 21/80\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0654 - accuracy: 0.6192 - val_loss: 1.2048 - val_accuracy: 0.5930\n",
      "Epoch 22/80\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.1242 - accuracy: 0.5930 - val_loss: 1.0411 - val_accuracy: 0.6302\n",
      "Epoch 23/80\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0742 - accuracy: 0.6163 - val_loss: 1.0605 - val_accuracy: 0.6143\n",
      "Epoch 23: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=80,\n",
    "                    validation_data=(test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.060469627380371, 0.6143215894699097]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.06\n",
      "accuracy: 61.43%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a cross-sectional deep model using Keras (with two or more hidden layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(10, return_sequences=True, input_shape=[n_steps, n_inputs] ),\n",
    "    keras.layers.SimpleRNN(12, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(13), \n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "175/175 [==============================] - 9s 40ms/step - loss: 1.1151 - accuracy: 0.5831 - val_loss: 1.1062 - val_accuracy: 0.5930\n",
      "Epoch 2/40\n",
      "175/175 [==============================] - 6s 37ms/step - loss: 1.1406 - accuracy: 0.5774 - val_loss: 1.1588 - val_accuracy: 0.5930\n",
      "Epoch 3/40\n",
      "175/175 [==============================] - 6s 32ms/step - loss: 1.1366 - accuracy: 0.5770 - val_loss: 1.1420 - val_accuracy: 0.5930\n",
      "Epoch 4/40\n",
      "175/175 [==============================] - 7s 39ms/step - loss: 1.0989 - accuracy: 0.5766 - val_loss: 1.0743 - val_accuracy: 0.5745\n",
      "Epoch 5/40\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 1.1104 - accuracy: 0.5727 - val_loss: 1.1265 - val_accuracy: 0.4116\n",
      "Epoch 6/40\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 1.0870 - accuracy: 0.5799 - val_loss: 1.0807 - val_accuracy: 0.5930\n",
      "Epoch 7/40\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 1.1355 - accuracy: 0.5774 - val_loss: 1.1538 - val_accuracy: 0.5930\n",
      "Epoch 8/40\n",
      "175/175 [==============================] - 6s 32ms/step - loss: 1.0908 - accuracy: 0.5761 - val_loss: 1.0703 - val_accuracy: 0.5737\n",
      "Epoch 9/40\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0878 - accuracy: 0.5899 - val_loss: 1.0775 - val_accuracy: 0.6219\n",
      "Epoch 10/40\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0874 - accuracy: 0.5847 - val_loss: 1.1294 - val_accuracy: 0.5930\n",
      "Epoch 11/40\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 1.1056 - accuracy: 0.5750 - val_loss: 1.0416 - val_accuracy: 0.5930\n",
      "Epoch 12/40\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 1.0597 - accuracy: 0.5777 - val_loss: 1.0810 - val_accuracy: 0.5930\n",
      "Epoch 13/40\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0289 - accuracy: 0.5915 - val_loss: 1.0502 - val_accuracy: 0.6164\n",
      "Epoch 14/40\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 1.1228 - accuracy: 0.5822 - val_loss: 1.1087 - val_accuracy: 0.5930\n",
      "Epoch 15/40\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.1409 - accuracy: 0.5774 - val_loss: 1.1069 - val_accuracy: 0.5930\n",
      "Epoch 16/40\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.1400 - accuracy: 0.5774 - val_loss: 1.1106 - val_accuracy: 0.5930\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=40,\n",
    "                    validation_data=(test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1106446981430054, 0.5929648280143738]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.11\n",
      "accuracy: 59.30%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a sequential shallow LSTM Model (with only one LSTM layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(10, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 7s 28ms/step - loss: 1.1081 - accuracy: 0.5734 - val_loss: 1.0208 - val_accuracy: 0.5930\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 1.0571 - accuracy: 0.6053 - val_loss: 1.0612 - val_accuracy: 0.6353\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 1.0704 - accuracy: 0.5917 - val_loss: 1.1310 - val_accuracy: 0.5930\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 1.0493 - accuracy: 0.5774 - val_loss: 1.0784 - val_accuracy: 0.5930\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 1.0346 - accuracy: 0.5870 - val_loss: 0.9534 - val_accuracy: 0.6390\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.9269 - accuracy: 0.6716 - val_loss: 0.9911 - val_accuracy: 0.6110\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.7191 - accuracy: 0.7633 - val_loss: 0.7211 - val_accuracy: 0.7596\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.6222 - accuracy: 0.8028 - val_loss: 0.6310 - val_accuracy: 0.7977\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.6515 - accuracy: 0.7900 - val_loss: 0.5870 - val_accuracy: 0.8065\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.5888 - accuracy: 0.8103 - val_loss: 0.6254 - val_accuracy: 0.8007\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 0.6010 - accuracy: 0.7990 - val_loss: 0.5383 - val_accuracy: 0.8233\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.5541 - accuracy: 0.8234 - val_loss: 0.8818 - val_accuracy: 0.6947\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.5372 - accuracy: 0.8275 - val_loss: 0.5198 - val_accuracy: 0.8346\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.5241 - accuracy: 0.8324 - val_loss: 0.4887 - val_accuracy: 0.8446\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.4944 - accuracy: 0.8392 - val_loss: 0.4696 - val_accuracy: 0.8467\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.5047 - accuracy: 0.8405 - val_loss: 0.5198 - val_accuracy: 0.8262\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 0.4747 - accuracy: 0.8489 - val_loss: 0.5616 - val_accuracy: 0.8329\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.5002 - accuracy: 0.8397 - val_loss: 0.4709 - val_accuracy: 0.8509\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.4580 - accuracy: 0.8570 - val_loss: 0.5796 - val_accuracy: 0.8145\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.4329 - accuracy: 0.8627 - val_loss: 0.4633 - val_accuracy: 0.8543\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.4262 - accuracy: 0.8595 - val_loss: 0.4434 - val_accuracy: 0.8652\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.4146 - accuracy: 0.8733 - val_loss: 0.5200 - val_accuracy: 0.8141\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.4477 - accuracy: 0.8582 - val_loss: 0.5073 - val_accuracy: 0.8476\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.5207 - accuracy: 0.8300 - val_loss: 0.4943 - val_accuracy: 0.8522\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.4643 - accuracy: 0.8532 - val_loss: 0.5283 - val_accuracy: 0.8275\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.4435 - accuracy: 0.8636 - val_loss: 0.4430 - val_accuracy: 0.8689\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.4291 - accuracy: 0.8670 - val_loss: 0.4031 - val_accuracy: 0.8861\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.4104 - accuracy: 0.8776 - val_loss: 0.4154 - val_accuracy: 0.8756\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.3982 - accuracy: 0.8794 - val_loss: 0.3907 - val_accuracy: 0.8882\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.3948 - accuracy: 0.8798 - val_loss: 0.3974 - val_accuracy: 0.8798\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.3887 - accuracy: 0.8816 - val_loss: 0.4122 - val_accuracy: 0.8840\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.3765 - accuracy: 0.8866 - val_loss: 0.4539 - val_accuracy: 0.8593\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.3771 - accuracy: 0.8857 - val_loss: 0.3864 - val_accuracy: 0.8890\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.3760 - accuracy: 0.8844 - val_loss: 0.3631 - val_accuracy: 0.8978\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.3653 - accuracy: 0.8873 - val_loss: 0.4166 - val_accuracy: 0.8777\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.3643 - accuracy: 0.8911 - val_loss: 0.4445 - val_accuracy: 0.8802\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.3945 - accuracy: 0.8792 - val_loss: 0.3867 - val_accuracy: 0.8903\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.3770 - accuracy: 0.8878 - val_loss: 0.3499 - val_accuracy: 0.8982\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.3560 - accuracy: 0.8905 - val_loss: 0.5584 - val_accuracy: 0.8321\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 0.3992 - accuracy: 0.8758 - val_loss: 0.3746 - val_accuracy: 0.8907\n",
      "Epoch 41/50\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 0.3665 - accuracy: 0.8905 - val_loss: 0.3891 - val_accuracy: 0.8987\n",
      "Epoch 42/50\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.3718 - accuracy: 0.8889 - val_loss: 0.4241 - val_accuracy: 0.8756\n",
      "Epoch 43/50\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.4190 - accuracy: 0.8735 - val_loss: 0.4961 - val_accuracy: 0.8375\n",
      "Epoch 43: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49611639976501465, 0.837520956993103]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.50\n",
      "accuracy: 83.75%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a sequential deep LSTM Model (with only two LSTM layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(6, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(7),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "175/175 [==============================] - 12s 52ms/step - loss: 1.1062 - accuracy: 0.5931 - val_loss: 1.0283 - val_accuracy: 0.6386\n",
      "Epoch 2/30\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 1.0560 - accuracy: 0.6181 - val_loss: 1.0450 - val_accuracy: 0.6353\n",
      "Epoch 3/30\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 0.9724 - accuracy: 0.6522 - val_loss: 0.8807 - val_accuracy: 0.6951\n",
      "Epoch 4/30\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.8116 - accuracy: 0.7037 - val_loss: 0.8329 - val_accuracy: 0.7111\n",
      "Epoch 5/30\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.7597 - accuracy: 0.7376 - val_loss: 0.7094 - val_accuracy: 0.7730\n",
      "Epoch 6/30\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 0.7128 - accuracy: 0.7514 - val_loss: 0.6812 - val_accuracy: 0.7747\n",
      "Epoch 7/30\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.6993 - accuracy: 0.7543 - val_loss: 0.7360 - val_accuracy: 0.7345\n",
      "Epoch 8/30\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.7639 - accuracy: 0.7367 - val_loss: 0.7179 - val_accuracy: 0.7613\n",
      "Epoch 9/30\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.7089 - accuracy: 0.7563 - val_loss: 0.6758 - val_accuracy: 0.7751\n",
      "Epoch 10/30\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.6797 - accuracy: 0.7721 - val_loss: 0.7335 - val_accuracy: 0.7299\n",
      "Epoch 11/30\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.6634 - accuracy: 0.7687 - val_loss: 0.6677 - val_accuracy: 0.7701\n",
      "Epoch 12/30\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.6463 - accuracy: 0.7696 - val_loss: 0.6364 - val_accuracy: 0.7772\n",
      "Epoch 13/30\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.6393 - accuracy: 0.7645 - val_loss: 0.6326 - val_accuracy: 0.7898\n",
      "Epoch 14/30\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.6643 - accuracy: 0.7635 - val_loss: 0.6467 - val_accuracy: 0.7642\n",
      "Epoch 15/30\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.6682 - accuracy: 0.7552 - val_loss: 0.6377 - val_accuracy: 0.7647\n",
      "Epoch 16/30\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.6351 - accuracy: 0.7658 - val_loss: 0.6254 - val_accuracy: 0.7936\n",
      "Epoch 17/30\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.7862 - accuracy: 0.7139 - val_loss: 0.6739 - val_accuracy: 0.7743\n",
      "Epoch 18/30\n",
      "175/175 [==============================] - 9s 54ms/step - loss: 0.6770 - accuracy: 0.7723 - val_loss: 0.8149 - val_accuracy: 0.6763\n",
      "Epoch 19/30\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.6879 - accuracy: 0.7832 - val_loss: 0.6928 - val_accuracy: 0.7718\n",
      "Epoch 20/30\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 1.0466 - accuracy: 0.6089 - val_loss: 1.0379 - val_accuracy: 0.5930\n",
      "Epoch 21/30\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 0.8762 - accuracy: 0.6701 - val_loss: 0.7315 - val_accuracy: 0.7496\n",
      "Epoch 21: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=30,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.731451153755188, 0.7495812177658081]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.73\n",
      "accuracy: 74.96%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a sequential deep LSTM Model (with only two LSTM layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(6, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 7s 28ms/step - loss: 1.1187 - accuracy: 0.5777 - val_loss: 1.0185 - val_accuracy: 0.5959\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 1.0345 - accuracy: 0.5942 - val_loss: 1.0146 - val_accuracy: 0.5766\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 5s 31ms/step - loss: 1.0190 - accuracy: 0.6027 - val_loss: 1.0369 - val_accuracy: 0.6235\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 1.0012 - accuracy: 0.6127 - val_loss: 0.9761 - val_accuracy: 0.6319\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.9889 - accuracy: 0.6262 - val_loss: 0.9834 - val_accuracy: 0.5992\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.9641 - accuracy: 0.6307 - val_loss: 1.0048 - val_accuracy: 0.6453\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 0.8788 - accuracy: 0.6784 - val_loss: 0.8608 - val_accuracy: 0.6847\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.7898 - accuracy: 0.7261 - val_loss: 0.8381 - val_accuracy: 0.6788\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 0.7311 - accuracy: 0.7480 - val_loss: 0.7058 - val_accuracy: 0.7563\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.7214 - accuracy: 0.7538 - val_loss: 0.6760 - val_accuracy: 0.7634\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.6922 - accuracy: 0.7651 - val_loss: 0.6498 - val_accuracy: 0.7810\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.6774 - accuracy: 0.7674 - val_loss: 0.6437 - val_accuracy: 0.7793\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.6621 - accuracy: 0.7834 - val_loss: 0.6292 - val_accuracy: 0.7998\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.6576 - accuracy: 0.7877 - val_loss: 0.7960 - val_accuracy: 0.7161\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.8203 - accuracy: 0.7073 - val_loss: 0.7769 - val_accuracy: 0.7178\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.7386 - accuracy: 0.7430 - val_loss: 0.7057 - val_accuracy: 0.7605\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.6565 - accuracy: 0.7810 - val_loss: 0.6006 - val_accuracy: 0.8057\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.6653 - accuracy: 0.7796 - val_loss: 0.6879 - val_accuracy: 0.7575\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 6s 32ms/step - loss: 0.6038 - accuracy: 0.7967 - val_loss: 0.5871 - val_accuracy: 0.8082\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 5s 31ms/step - loss: 0.7191 - accuracy: 0.7597 - val_loss: 0.6118 - val_accuracy: 0.7973\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6117503046989441, 0.7973199486732483]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.61\n",
      "accuracy: 79.73%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a sequential deep GRU Model (with only two GRU layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(6, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(8),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "175/175 [==============================] - 13s 56ms/step - loss: 1.1036 - accuracy: 0.5844 - val_loss: 1.0027 - val_accuracy: 0.6089\n",
      "Epoch 2/30\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.9592 - accuracy: 0.6287 - val_loss: 0.8497 - val_accuracy: 0.6566\n",
      "Epoch 3/30\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.7134 - accuracy: 0.7416 - val_loss: 0.8896 - val_accuracy: 0.6692\n",
      "Epoch 4/30\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 0.5699 - accuracy: 0.8214 - val_loss: 0.5192 - val_accuracy: 0.8472\n",
      "Epoch 5/30\n",
      "175/175 [==============================] - 8s 48ms/step - loss: 0.5413 - accuracy: 0.8333 - val_loss: 0.4966 - val_accuracy: 0.8522\n",
      "Epoch 6/30\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 0.5643 - accuracy: 0.8191 - val_loss: 0.5630 - val_accuracy: 0.8342\n",
      "Epoch 7/30\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.5023 - accuracy: 0.8460 - val_loss: 0.5225 - val_accuracy: 0.8258\n",
      "Epoch 8/30\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.4622 - accuracy: 0.8543 - val_loss: 0.5920 - val_accuracy: 0.7902\n",
      "Epoch 9/30\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.4320 - accuracy: 0.8606 - val_loss: 0.4576 - val_accuracy: 0.8463\n",
      "Epoch 10/30\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 0.4146 - accuracy: 0.8609 - val_loss: 0.4457 - val_accuracy: 0.8425\n",
      "Epoch 11/30\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.3932 - accuracy: 0.8758 - val_loss: 0.3821 - val_accuracy: 0.8798\n",
      "Epoch 12/30\n",
      "175/175 [==============================] - 10s 55ms/step - loss: 0.3835 - accuracy: 0.8810 - val_loss: 0.5364 - val_accuracy: 0.8455\n",
      "Epoch 13/30\n",
      "175/175 [==============================] - 10s 60ms/step - loss: 0.3819 - accuracy: 0.8765 - val_loss: 0.3775 - val_accuracy: 0.8890\n",
      "Epoch 14/30\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.3663 - accuracy: 0.8903 - val_loss: 0.3706 - val_accuracy: 0.8920\n",
      "Epoch 15/30\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.3474 - accuracy: 0.8997 - val_loss: 0.3515 - val_accuracy: 0.8941\n",
      "Epoch 16/30\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 0.3454 - accuracy: 0.8977 - val_loss: 0.3393 - val_accuracy: 0.9028\n",
      "Epoch 17/30\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.3352 - accuracy: 0.9002 - val_loss: 0.3269 - val_accuracy: 0.9100\n",
      "Epoch 18/30\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 0.3379 - accuracy: 0.9022 - val_loss: 0.3896 - val_accuracy: 0.8882\n",
      "Epoch 19/30\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 0.3384 - accuracy: 0.8975 - val_loss: 0.4893 - val_accuracy: 0.8350\n",
      "Epoch 20/30\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.3398 - accuracy: 0.8993 - val_loss: 0.3358 - val_accuracy: 0.9049\n",
      "Epoch 21/30\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.3333 - accuracy: 0.9013 - val_loss: 0.3246 - val_accuracy: 0.9058\n",
      "Epoch 22/30\n",
      "175/175 [==============================] - 8s 48ms/step - loss: 0.3315 - accuracy: 0.9033 - val_loss: 0.3595 - val_accuracy: 0.9012\n",
      "Epoch 23/30\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.3241 - accuracy: 0.9054 - val_loss: 0.4018 - val_accuracy: 0.8740\n",
      "Epoch 24/30\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 0.3634 - accuracy: 0.8920 - val_loss: 0.3227 - val_accuracy: 0.9095\n",
      "Epoch 25/30\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 0.3208 - accuracy: 0.9038 - val_loss: 0.3107 - val_accuracy: 0.9116\n",
      "Epoch 26/30\n",
      "175/175 [==============================] - 11s 62ms/step - loss: 0.3231 - accuracy: 0.9034 - val_loss: 0.3377 - val_accuracy: 0.9045\n",
      "Epoch 27/30\n",
      "175/175 [==============================] - 11s 64ms/step - loss: 0.3411 - accuracy: 0.8993 - val_loss: 0.3026 - val_accuracy: 0.9129\n",
      "Epoch 28/30\n",
      "175/175 [==============================] - 10s 54ms/step - loss: 0.3143 - accuracy: 0.9095 - val_loss: 0.4448 - val_accuracy: 0.8719\n",
      "Epoch 29/30\n",
      "175/175 [==============================] - 10s 55ms/step - loss: 0.3144 - accuracy: 0.9083 - val_loss: 0.3265 - val_accuracy: 0.9083\n",
      "Epoch 30/30\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 0.3059 - accuracy: 0.9094 - val_loss: 0.3115 - val_accuracy: 0.9091\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=30,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31149041652679443, 0.9091289639472961]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.31\n",
      "accuracy: 90.91%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test values of each model "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below  are the test accuracy values for each model\n",
    "\n",
    "1. cross-sectional shallow model using Keras (with only one hidden layer)\n",
    "accuracy: 61.43%\n",
    "\n",
    "2. cross-sectional deep model using Keras (with two or more hidden layers)\n",
    "accuracy: 59.30%\n",
    "\n",
    "3. LSTM Model (with only one LSTM layer)\n",
    "accuracy: 83.75%\n",
    "\n",
    "4. deep LSTM Model (with only two LSTM layers)\n",
    "accuracy: 74.96%\n",
    "\n",
    "5. GRU Model (with only one GRU layer)\n",
    "accuracy: 79.73%\n",
    "\n",
    "6. deep GRU Model (with only two GRU layers) \n",
    "accuracy: 90.91%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model performance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this case, Deep GRU Model performs the best because if we compare accuracy of this model to every other model, it is higher among all. Also baseline accuracy is 58% which means the model which performs with higher accuracy than 58% is a good model. Accuracy of Deep GRU model is 90.91% which is higher than 58%. That's why this model performs the best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
